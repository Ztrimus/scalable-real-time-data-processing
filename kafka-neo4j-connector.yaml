apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-neo4j-files
data:
  init.sh: |
    #!/bin/sh
    # Start Kafka Connect in background
    /etc/confluent/docker/run &
    CONNECT_PID=$!

    # Wait for Kafka Connect listener
    echo "Waiting for Kafka Connect to start listening on localhost ⏳"

    while : ; do
      curl_status=$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
      echo -e $(date) " Kafka Connect listener HTTP state: " $curl_status " (waiting for 200)"
      if [ $curl_status -eq 200 ] ; then
        break
      fi
      sleep 5 
    done

    echo -e "\n--\n+> Creating Data Generator source - 1"

    curl -X POST http://localhost:8083/connectors/ -H "Content-Type:application/json" -H "Accept:application/json" -d @/config/sink.neo4j.json

    # Wait for Kafka Connect to keep container alive
    wait $CONNECT_PID
  sink.neo4j.json: |
    {
      "name": "Neo4jSinkConnectorJSONString",
      "config": {
        "topics": "nyc_taxicab_data",
        "connector.class": "streams.kafka.connect.sink.Neo4jSinkConnector",
        "key.converter": "org.apache.kafka.connect.json.JsonConverter",
        "key.converter.schemas.enable": false,
        "value.converter": "org.apache.kafka.connect.json.JsonConverter",
        "value.converter.schemas.enable": false,
        "errors.retry.timeout": "-1",
        "errors.retry.delay.max.ms": "1000",
        "errors.tolerance": "all",
        "errors.log.enable": true,
        "errors.log.include.messages": true,
        "neo4j.server.uri": "bolt://neo4j-service:7687",
        "neo4j.authentication.basic.username": "neo4j",
        "neo4j.authentication.basic.password": "project1phase2",
        "neo4j.topic.cypher.nyc_taxicab_data": "MERGE (p:Location {name: toInteger(event.PULocationID)}) MERGE (d:Location {name: toInteger(event.DOLocationID)}) MERGE (p)-[:TRIP {distance: toFloat(event.trip_distance), fare: toFloat(event.fare_amount)}]->(d)"
      }
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-neo4j-connector
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kafka-neo4j-connector
  template:
    metadata:
      labels:
        app: kafka-neo4j-connector
    spec:
      initContainers:
        - name: init-kafka-topics
          image: bitnami/kafka:3.5.0
          command: ["/bin/bash", "-c"]
          args:
            - |
              kafka-topics.sh --create --topic connect-offsets \
                --bootstrap-server kafka-service:9092 \
                --partitions 1 --replication-factor 1 \
                --config cleanup.policy=compact || true;
              
              kafka-topics.sh --create --topic connect-configs \
                --bootstrap-server kafka-service:9092 \
                --partitions 1 --replication-factor 1 \
                --config cleanup.policy=compact || true;
              
              kafka-topics.sh --create --topic connect-statuses \
                --bootstrap-server kafka-service:9092 \
                --partitions 1 --replication-factor 1 \
                --config cleanup.policy=compact || true;
      containers:
        - name: kafka-neo4j-connector
          image: kafka-neo4j-custom-connect:latest
          imagePullPolicy: Never # after pushing to Docker Hub, change to IfNotPresent
          # image: confluentinc/cp-kafka-connect:7.3.3
          # image: veedata/kafka-neo4j-connect
          ports:
            - containerPort: 8083
          command: ["/bin/sh", "-c"]
          args: ["sh /config/init.sh"]
          env:
          - name: KAFKA_BOOTSTRAP_SERVERS
            value: kafka-service:9092
          - name: CONNECT_PLUGIN_PATH
            value: /usr/share/java,/etc/kafka-connect/jars
          - name: CONNECT_BOOTSTRAP_SERVERS
            value: kafka-service:9092
          - name: CONNECT_REST_ADVERTISED_HOST_NAME
          #   value: "kafka-connect"
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: CONNECT_GROUP_ID
            value: "kafka-connect"
          - name: CONNECT_CONFIG_STORAGE_TOPIC
            value: "connect-configs"
          - name: CONNECT_OFFSET_STORAGE_TOPIC
            value: "connect-offsets"
          - name: CONNECT_STATUS_STORAGE_TOPIC
            value: "connect-statuses"
          - name: CONNECT_KEY_CONVERTER
            value: "org.apache.kafka.connect.storage.StringConverter"
          - name: CONNECT_VALUE_CONVERTER
            value: "org.apache.kafka.connect.json.JsonConverter"
          - name: CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE
            value: "false"
          - name: CONNECT_LOG4J_LOGGERS
            value: "org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR"
          - name: CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN
            value: "[%d] %p %X{connector.context}%m (%c:%L)%n"
          - name: CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR
            value: "1"
          - name: CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR
            value: "1"
          - name: CONNECT_STATUS_STORAGE_REPLICATION_FACTOR
            value: "1"
          volumeMounts:
            - name: connector-config
              mountPath: /config
      volumes:
        - name: connector-config
          configMap:
            name: kafka-neo4j-files